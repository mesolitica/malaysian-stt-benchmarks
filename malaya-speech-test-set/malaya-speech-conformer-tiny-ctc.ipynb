{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a887e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/huseinzol05/malaya-speech-stt-test-set/resolve/main/malaya-speech/malay-test.tar.gz\n",
    "# !tar -zxf malay-test.tar.gz\n",
    "# !wget https://huggingface.co/datasets/huseinzol05/malaya-speech-stt-test-set/resolve/main/malaya-speech/malaya-malay-test-set.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c1d04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "/home/husein/.local/lib/python3.8/site-packages/whisper/timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n",
      "`pyaudio` is not available, `malaya_speech.streaming.pyaudio` is not able to use.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "import malaya_speech\n",
    "import json\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "vocabs = [\" \", \"a\", \"e\", \"n\", \"i\", \"t\", \"o\", \"u\", \"s\", \"k\", \"r\", \"l\", \"h\", \"d\", \"m\", \"g\", \"y\", \"b\", \"p\", \"w\", \"c\", \"f\", \"j\", \"v\", \"z\", \"0\", \"1\", \"x\", \"2\", \"q\", \"5\", \"3\", \"4\", \"6\", \"9\", \"8\", \"7\"]\n",
    "\n",
    "def preprocessing_text(string):\n",
    "    \n",
    "    string = unicodedata.normalize('NFC', string.lower())\n",
    "    string = ''.join([c if c in vocabs else ' ' for c in string])\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip()\n",
    "    string = (\n",
    "        ''.join(''.join(s)[:2] for _, s in itertools.groupby(string))\n",
    "    )\n",
    "    return string\n",
    "\n",
    "def calculate_cer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate CER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    actual = actual.replace(' ', '')\n",
    "    hyp = hyp.replace(' ', '')\n",
    "    return Lev.distance(actual, hyp) / len(actual)\n",
    "\n",
    "\n",
    "def calculate_wer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate WER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    b = set(actual.split() + hyp.split())\n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "\n",
    "    w1 = [chr(word2char[w]) for w in actual.split()]\n",
    "    w2 = [chr(word2char[w]) for w in hyp.split()]\n",
    "\n",
    "    return Lev.distance(''.join(w1), ''.join(w2)) / len(actual.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a880cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained('mesolitica/conformer-tiny-ctc', trust_remote_code = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f5715d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyctcdecode import build_ctcdecoder\n",
    "from huggingface_hub import hf_hub_download\n",
    "import kenlm\n",
    "import torchaudio\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ebbd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_CTC_VOCAB = [\n",
    "    '',\n",
    "    'a',\n",
    "    'b',\n",
    "    'c',\n",
    "    'd',\n",
    "    'e',\n",
    "    'f',\n",
    "    'g',\n",
    "    'h',\n",
    "    'i',\n",
    "    'j',\n",
    "    'k',\n",
    "    'l',\n",
    "    'm',\n",
    "    'n',\n",
    "    'o',\n",
    "    'p',\n",
    "    'q',\n",
    "    'r',\n",
    "    's',\n",
    "    't',\n",
    "    'u',\n",
    "    'v',\n",
    "    'w',\n",
    "    'x',\n",
    "    'y',\n",
    "    'z',\n",
    "    '0',\n",
    "    '1',\n",
    "    '2',\n",
    "    '3',\n",
    "    '4',\n",
    "    '5',\n",
    "    '6',\n",
    "    '7',\n",
    "    '8',\n",
    "    '9',\n",
    "    ' ',\n",
    "    '?',\n",
    "    '_'\n",
    "]\n",
    "HF_CTC_VOCAB_INDEX = {no: c for no, c in enumerate(HF_CTC_VOCAB)}\n",
    "HF_CTC_VOCAB_REV = {v: k for k, v in HF_CTC_VOCAB_INDEX.items()}\n",
    "\n",
    "DECIBEL = 2 * 20 * math.log10(torch.iinfo(torch.int16).max)\n",
    "GAIN = pow(10, 0.05 * DECIBEL)\n",
    "\n",
    "spectrogram_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000, n_fft=400, n_mels=80, hop_length=160)\n",
    "\n",
    "\n",
    "def piecewise_linear_log(x):\n",
    "    x = x * GAIN\n",
    "    x[x > math.e] = torch.log(x[x > math.e])\n",
    "    x[x <= math.e] = x[x <= math.e] / math.e\n",
    "    return x\n",
    "\n",
    "\n",
    "def melspectrogram(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        x = torch.Tensor(x)\n",
    "    x = spectrogram_transform(x).transpose(1, 0)\n",
    "    return piecewise_linear_log(x)\n",
    "\n",
    "lm = hf_hub_download('mesolitica/kenlm-pseudolabel-whisper-large-v3', 'out.binary')\n",
    "kenlm_model = kenlm.Model(lm)\n",
    "decoder = build_ctcdecoder(\n",
    "    HF_CTC_VOCAB,\n",
    "    kenlm_model,\n",
    "    alpha=0.2,\n",
    "    beta=1.0,\n",
    "    ctc_token_idx=len(HF_CTC_VOCAB) - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e75a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-15.2894,  -0.8834,   0.9386,  ...,  -3.7483, -15.3320,   3.7056],\n",
       "          [-16.8735,   2.9311,  -1.9171,  ...,  -1.3749, -16.8303,   4.7868],\n",
       "          [-16.8715,   0.9151,  -1.1347,  ...,  -0.3149, -16.8906,   4.5809],\n",
       "          ...,\n",
       "          [-14.9632,   0.6289,  -1.2577,  ...,  -2.8886, -15.0917,   3.8999],\n",
       "          [-16.8317,   2.8282,  -3.0190,  ...,  -2.0569, -16.8586,   4.4275],\n",
       "          [-17.3873,   0.4810,  -2.5573,  ...,  -0.3014, -17.4308,   4.5122]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([125]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel = melspectrogram(np.zeros((16000 * 5,)))\n",
    "inputs = {\n",
    "    'inputs': mel.unsqueeze(0),\n",
    "    'lengths': torch.tensor([len(mel)])\n",
    "}\n",
    "model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8150fba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "765"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('malaya-malay-test-set.json') as fopen:\n",
    "    data = json.load(fopen)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "023289a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 765/765 [00:26<00:00, 28.95it/s]\n"
     ]
    }
   ],
   "source": [
    "wer, cer = [], []\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    \n",
    "    if not data[i]['accept']:\n",
    "        continue\n",
    "        \n",
    "    f = f'malay-test/{i}.wav'\n",
    "    actual = data[i]['cleaned']\n",
    "    \n",
    "    y, _ = malaya_speech.load(f)\n",
    "    \n",
    "    mel = melspectrogram(y)\n",
    "    inputs = {\n",
    "        'inputs': mel.unsqueeze(0),\n",
    "        'lengths': torch.tensor([len(mel)])\n",
    "    }\n",
    "    r = model(**inputs)\n",
    "    logits = r[0].detach().numpy()\n",
    "    out = decoder.decode_beams(logits[0], prune_history=True)\n",
    "    out, lm_state, timesteps, logit_score, lm_score = out[0]\n",
    "    \n",
    "    out = preprocessing_text(out)\n",
    "        \n",
    "    actual = actual.lower()\n",
    "    out = out.lower()\n",
    "    \n",
    "    wer.append(calculate_wer(actual, out))\n",
    "    cer.append(calculate_cer(actual, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2ea0a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21302693966628394, 0.0612581761581601)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wer), np.mean(cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3997226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
